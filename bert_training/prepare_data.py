import pandas as pd
import os
from sklearn.model_selection import train_test_split

# ğŸ“‚ æ•°æ®è·¯å¾„ (ä½¿ç”¨åŸºäºæ–‡ä»¶ä½ç½®çš„è·¯å¾„)
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # è·å–é¡¹ç›®æ ¹ç›®å½•
DATA_PATH = os.path.join(BASE_DIR, "data", "dataset_bert.csv")
TRAIN_PATH = os.path.join(BASE_DIR, "data", "train.csv")
VAL_PATH = os.path.join(BASE_DIR, "data", "val.csv")


def load_and_check_data(file_path):
    """åŠ è½½ CSV æ–‡ä»¶ã€æ£€æŸ¥å­—æ®µï¼Œå¹¶è¿›è¡Œæ•°æ®æ¸…æ´—"""
    df = pd.read_csv(file_path, encoding="utf-8-sig", sep=";")  # ğŸ‘ˆ æŒ‡å®šåˆ†éš”ç¬¦ä¸ºåˆ†å·

    # âœ… æ£€æŸ¥å¿…è¦å­—æ®µ
    required_columns = ["text", "category"]
    for col in required_columns:
        if col not in df.columns:
            raise ValueError(f"âŒ ç¼ºå°‘å¿…è¦å­—æ®µ: {col}")

    # ğŸ§¹ æ•°æ®æ¸…æ´—
    df = df.dropna()  # ç§»é™¤ç©ºå€¼
    df["text"] = df["text"].str.strip()  # å»é™¤æ–‡æœ¬ä¸­çš„å¤šä½™ç©ºæ ¼

    print("ğŸ“‹ æ•°æ®é¢„è§ˆï¼š")
    print(df.head())
    print("\nğŸ“Š æ•°æ®ç»Ÿè®¡ä¿¡æ¯ï¼š")
    print(df.info())

    return df


def split_and_save_data(df, train_path, val_path):
    """å°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œå¹¶ä¿å­˜ä¸º CSV æ–‡ä»¶"""
    # ğŸ”€ æ•°æ®é›†åˆ’åˆ† (80% è®­ç»ƒé›†, 20% éªŒè¯é›†)
    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)

    # ğŸ’¾ ä¿å­˜æ•°æ®é›†
    train_df.to_csv(train_path, index=False, encoding="utf-8-sig")
    val_df.to_csv(val_path, index=False, encoding="utf-8-sig")

    print("\nâœ… è®­ç»ƒé›†å’ŒéªŒè¯é›†å·²ä¿å­˜è‡³ data æ–‡ä»¶å¤¹")


if __name__ == "__main__":
    # ğŸ“‚ æ–‡ä»¶è·¯å¾„æ£€æŸ¥
    print("ğŸ“‚ å½“å‰å·¥ä½œç›®å½•:", os.getcwd())
    print("ğŸ“‚ ç›®æ ‡è·¯å¾„:", DATA_PATH)

    if not os.path.exists(DATA_PATH):
        raise FileNotFoundError(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {DATA_PATH}")

    df = load_and_check_data(DATA_PATH)

    # æ•°æ®é›†åˆ’åˆ†ä¸ä¿å­˜
    split_and_save_data(df, TRAIN_PATH, VAL_PATH)
    print("\nâœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼")
